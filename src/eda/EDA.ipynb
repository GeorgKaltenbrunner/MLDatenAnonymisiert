{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee58ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('/Users/georgkaltenbrunner/python/MLDatenAnonymisiert/data/raw/Bank_Customer_Churn_Prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9995f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train(dataset):\n",
    "    y = dataset['churn']\n",
    "    X = dataset.drop('churn', axis= 1)\n",
    "    return train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0361ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = test_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0579fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Age\n",
    "\n",
    "def age_group(df) -> pd.DataFrame:\n",
    "    bins = [0, 10, 18, 30, 50, 65, float(\"inf\")]\n",
    "    labels = [\"0-10\", \"11-18\", \"19-30\", \"31-50\", \"51-65\", \"66+\"]\n",
    "\n",
    "    df[\"age_group\"] = pd.cut(df[\"age\"], bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "    return df\n",
    "\n",
    "# CreditSccore\n",
    "\n",
    "def credit_score_group(df) -> pd.DataFrame:\n",
    "    bins = [350, 550,  750, float(\"inf\")]\n",
    "    labels = [0, 1, 2]\n",
    "\n",
    "    df[\"credit_score_group\"] = pd.cut(df[\"credit_score\"], bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "    return df\n",
    "\n",
    "# estimated_salary Quartile\n",
    "\n",
    "def estimated_salary_quartile(df) -> pd.DataFrame:\n",
    "    df[\"salary_quartile\"] = pd.qcut(df[\"estimated_salary\"], q=4, labels=[1, 2, 3, 4])\n",
    "    return df\n",
    "\n",
    "# Tenure einteilen in \"Junge Kund:innen\" vs. Bestandskund:inne\n",
    "def tenure_groups(df) -> pd.DataFrame:\n",
    "    df[\"kunden_typ\"] = np.where(df[\"tenure\"] < 2, \"Junge Kund:in\", \"Bestandskund:in\")\n",
    "    return df\n",
    "\n",
    "# Balance Estimated Salary Ratio\n",
    "def balance_salray_ratio(df) -> pd.DataFrame:\n",
    "    df[\"balance_salary_ratio\"] = df[\"balance\"] / df[\"estimated_salary\"]\n",
    "    return df\n",
    "\n",
    "# Balance Product Ratio\n",
    "def balance_product_ratio(df) -> pd.DataFrame:\n",
    "    df[\"balance_product_ratio\"] = df[\"balance\"] / df[\"products_number\"]\n",
    "    return df\n",
    "\n",
    "# Credit Score Age Ratio\n",
    "def credit_score_age_ratio(df) -> pd.DataFrame:\n",
    "    df[\"credit_score_age_ratio\"] = df[\"credit_score\"] / df[\"age\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_enigneering_pipeline_all_features(df) -> pd.DataFrame:\n",
    "    # Age\n",
    "    df = age_group(df)\n",
    "    # CreditSccore\n",
    "    df = credit_score_group(df)\n",
    "    # estimated_salary Quartile\n",
    "    df = estimated_salary_quartile(df)\n",
    "    # Tenure\n",
    "    df = tenure_groups(df)\n",
    "    # Balance Estimated Salary Ratio\n",
    "    df = balance_salray_ratio(df)\n",
    "    # Balance Product Ratio\n",
    "    df = balance_product_ratio(df)\n",
    "    # Credit Score Age Ratio\n",
    "    df = credit_score_age_ratio(df)    \n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8621c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = feature_enigneering_pipeline_all_features(X_train)\n",
    "X_test_encoded = feature_enigneering_pipeline_all_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e803aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3300 entries, 6252 to 9401\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   customer_id             3300 non-null   int64   \n",
      " 1   credit_score            3300 non-null   int64   \n",
      " 2   country                 3300 non-null   object  \n",
      " 3   gender                  3300 non-null   object  \n",
      " 4   age                     3300 non-null   int64   \n",
      " 5   tenure                  3300 non-null   int64   \n",
      " 6   balance                 3300 non-null   float64 \n",
      " 7   products_number         3300 non-null   int64   \n",
      " 8   credit_card             3300 non-null   int64   \n",
      " 9   active_member           3300 non-null   int64   \n",
      " 10  estimated_salary        3300 non-null   float64 \n",
      " 11  age_group               3300 non-null   category\n",
      " 12  credit_score_group      3300 non-null   category\n",
      " 13  salary_quartile         3300 non-null   category\n",
      " 14  kunden_typ              3300 non-null   object  \n",
      " 15  balance_salary_ratio    3300 non-null   float64 \n",
      " 16  balance_product_ratio   3300 non-null   float64 \n",
      " 17  credit_score_age_ratio  3300 non-null   float64 \n",
      "dtypes: category(3), float64(5), int64(7), object(3)\n",
      "memory usage: 422.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb2eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5760138622053618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logisitsche Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "categorical_features = ['country', 'gender', 'age_group', 'credit_score_group', 'salary_quartile', 'kunden_typ']\n",
    "numeric_features = ['estimated_salary', 'balance'] \n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing definieren\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "# Pipeline mit Logistic Regression\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "# Trainiere das Modell\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage auf Testdaten\n",
    "y_pred = pipeline.predict(X_test)\n",
    "f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a16f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5; 1/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 4/5; 1/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 3/5; 1/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 5/5; 1/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 3/5; 2/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 2/5; 1/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 2/5; 2/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 1/5; 2/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 4/5; 1/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.587 total time=   0.7s\n",
      "[CV 1/5; 1/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.560 total time=   0.7s\n",
      "[CV 5/5; 1/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.560 total time=   0.7s\n",
      "[CV 4/5; 2/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 3/5; 1/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.564 total time=   0.8s\n",
      "[CV 5/5; 2/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 1/5; 3/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100\n",
      "[CV 2/5; 3/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100\n",
      "[CV 2/5; 1/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.570 total time=   0.7s\n",
      "[CV 3/5; 3/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100\n",
      "[CV 1/5; 3/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.564 total time=   0.6s\n",
      "[CV 4/5; 3/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100\n",
      "[CV 3/5; 2/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200;, score=0.564 total time=   1.4s\n",
      "[CV 2/5; 3/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.562 total time=   0.7s\n",
      "[CV 5/5; 3/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100\n",
      "[CV 3/5; 3/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.560 total time=   0.7s\n",
      "[CV 1/5; 2/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200;, score=0.559 total time=   1.4s\n",
      "[CV 1/5; 4/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200\n",
      "[CV 2/5; 2/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200;, score=0.563 total time=   1.5s\n",
      "[CV 2/5; 4/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200\n",
      "[CV 3/5; 4/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200\n",
      "[CV 4/5; 4/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200\n",
      "[CV 4/5; 2/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200;, score=0.579 total time=   1.4s\n",
      "[CV 4/5; 3/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.582 total time=   0.7s\n",
      "[CV 5/5; 4/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200\n",
      "[CV 5/5; 3/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.570 total time=   0.8s\n",
      "[CV 1/5; 5/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 2/5; 5/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 5/5; 2/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=200;, score=0.562 total time=   1.5s\n",
      "[CV 3/5; 5/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 2/5; 5/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.568 total time=   0.7s\n",
      "[CV 1/5; 5/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.572 total time=   0.7s\n",
      "[CV 4/5; 5/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 3/5; 5/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.560 total time=   0.7s\n",
      "[CV 3/5; 4/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.553 total time=   1.3s\n",
      "[CV 2/5; 4/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.564 total time=   1.3s\n",
      "[CV 5/5; 5/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100\n",
      "[CV 1/5; 6/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 2/5; 6/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 3/5; 6/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 4/5; 4/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.577 total time=   1.4s\n",
      "[CV 4/5; 6/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 1/5; 4/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.560 total time=   1.6s\n",
      "[CV 5/5; 6/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=200\n",
      "[CV 5/5; 4/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.570 total time=   1.3s\n",
      "[CV 1/5; 7/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100\n",
      "[CV 5/5; 5/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.572 total time=   0.6s\n",
      "[CV 2/5; 7/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100\n",
      "[CV 4/5; 5/48] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100;, score=0.584 total time=   0.8s\n",
      "[CV 3/5; 7/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100\n",
      "[CV 4/5; 7/48] START classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m grid_search = GridSearchCV(pipeline, param_grid, cv=\u001b[32m5\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mf1_macro\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m24\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Beste Parameter\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBeste Parameterkombination:\u001b[39m\u001b[33m\"\u001b[39m, grid_search.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Merkmale definieren\n",
    "categorical_features = ['country', 'gender', 'age_group', 'credit_score_group', 'salary_quartile', 'kunden_typ']\n",
    "numeric_features = ['estimated_salary', 'balance'] \n",
    "\n",
    "# Preprocessing definieren\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "# Pipeline definieren\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "# Hyperparameter-Raster für Grid Search\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [10, 50, None],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2],\n",
    "    'classifier__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Grid Search mit F1-Score als Bewertungsmaß\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', n_jobs=-1, verbose=24)\n",
    "\n",
    "# Training\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Beste Parameter\n",
    "print(\"Beste Parameterkombination:\", grid_search.best_params_)\n",
    "\n",
    "# Vorhersage und Bewertung\n",
    "y_pred = grid_search.predict(X_test)\n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1-Score (macro):\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace09ddf",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/georgkaltenbrunner/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <98D50080-9632-3EA4-B874-146E55453763> /Users/georgkaltenbrunner/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, StandardScaler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/xgboost/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Booster,\n\u001b[32m     10\u001b[39m     DataIter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     build_info,\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/xgboost/tracker.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/xgboost/core.py:295\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m _LIB = \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    299\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    300\u001b[39m \n\u001b[32m    301\u001b[39m \u001b[33;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m \u001b[33;03m        return value from API calls\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/xgboost/core.py:257\u001b[39m, in \u001b[36m_load_lib\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[32m    256\u001b[39m         libname = os.path.basename(lib_paths[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[32m    258\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[33mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) could not be loaded.\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[33mLikely causes:\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[33m  * OpenMP runtime is not installed\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[33m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[33m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[33m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[33m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[32m    266\u001b[39m \n\u001b[32m    267\u001b[39m \u001b[33m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[32m    268\u001b[39m \n\u001b[32m    269\u001b[39m \u001b[33mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    271\u001b[39m         )\n\u001b[32m    272\u001b[39m     _register_log_callback(lib)\n\u001b[32m    274\u001b[39m     libver = _lib_version(lib)\n",
      "\u001b[31mXGBoostError\u001b[39m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/georgkaltenbrunner/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <98D50080-9632-3EA4-B874-146E55453763> /Users/georgkaltenbrunner/python/MLDatenAnonymisiert/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Features definieren\n",
    "categorical_features = ['country', 'gender', 'age_group', 'credit_score_group', 'salary_quartile', 'kunden_typ']\n",
    "numeric_features = ['estimated_salary', 'balance']\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "# Pipeline mit XGBoost\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=0))\n",
    "])\n",
    "\n",
    "# Hyperparameter-Tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [3, 6, 10],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.3],\n",
    "    'classifier__subsample': [0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Trainieren\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Beste Parameter\n",
    "print(\"Beste Parameterkombination:\", grid_search.best_params_)\n",
    "\n",
    "# Vorhersage & Bewertung\n",
    "y_pred = grid_search.predict(X_test)\n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1-Score (macro):\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9966b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
